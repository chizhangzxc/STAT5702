sampled_state <- mean(sample(state_space,n,TRUE,prob=L))
Q_table <- .5 * (Q_a + Q_b)
ek <- max(.1,.999^k)
if (runif(1) > ek)
chosen_action <- action_space[which.min(Q_table[which(state_space==state),])] else
chosen_action <- sample(action_space,1)
r <- (.2 + sampled_state) * state + .5 * chosen_action
beta <- learning_rate(state,chosen_action,num_visited)
st <- ifelse(chosen_action==1,0,sample(state_space[which(state_space==state):(B+1)],1))
# Q_prime <- mellowmax(Q_table[which(state_space==st),],omega = -300)
if(runif(1)<.5)
Q_a[which(state_space==state),chosen_action+1] <- (1-beta) * Q_a[which(state_space==state),chosen_action+1] +
beta*(r + discount_factor*min(Q_b[which(state_space==st),]))      else
Q_b[which(state_space==state),chosen_action+1] <- (1-beta) * Q_b[which(state_space==state),chosen_action+1] +
beta*(r + discount_factor*min(Q_a[which(state_space==st),]))
# Q_table[which(state_space==state),chosen_action+1] <- (1-beta) * Q_table[which(state_space==state),chosen_action+1] +
#   beta*(r + discount_factor*min(Q_table[which(state_space==st),]))
# Q_table[which(state_space==state),chosen_action+1] <- (1-beta) * Q_table[which(state_space==state),chosen_action+1] +
#   beta*(r + discount_factor * Q_prime)
num_visited[which(state_space==state),chosen_action+1] <- num_visited[which(state_space==state),chosen_action+1] + 1
state <- st
}
Q_table <- .5 *(Q_a+Q_b)
pi <- sapply(state_space,FUN = soft_max)
P <- NULL
for (i in 1:(B+1))
{
P <- cbind(P,pi[,i] * L[i])
}
L_prime <- t(P[2,] %*% t(transition_1) + P[1,] %*% t(transition_0))
L_prime <- trunc(L_prime*10^6)/10^6
L <- L_prime
v <- apply(Q_table,1,min)
fit <- lm(v ~ state_space)
seg_fit <- segmented(fit)
policy[sample_path, iteration] <- seg_fit$psi[2]
performance[sample_path, iteration] <- mean(apply(Q_table,1,min))
mean_field[sample_path, iteration] <- sum(L*state_space)
print(c(sample_path, iteration, policy[sample_path, iteration], performance[sample_path, iteration], mean_field[sample_path,iteration]))
}
value <- rbind(value, apply(Q_table, 1, min))
}
library(segmented)
discount_factor <- .9
B <- 100
state_space <- seq(0,1,by=1/B)
action_space <- 0:1
n <- 100
options(scipen=999)
soft_max <- function(state, c=-2)
{
state <- round(state*B+1)
prob <- exp(c*Q_table[state,])
prob <- prob/sum(prob)
return(prob)
}
learning_rate <- function(state,action,num_visited,h=.55)
{
state <- round(state*B+1)
action <- round(action + 1)
return((num_visited[state,action]+1)^-h)
}
mellowmax <- function(Q, omega)
{
m <- max(Q)
Q <- Q - m
return(log(mean(exp(omega * Q)))/omega + m)
}
transition_0 <- NULL
transition_1 <- NULL
for (i in 1:length(state_space))
{
transition_1 <- cbind(transition_1, c(1,rep(0,B)))
}
for (i in 1:length(state_space))
{
transition_0 <- cbind(transition_0, c(rep(0,i-1), rep(1/(B-i+2),B-i+2)))
}
policy <- matrix(0,nrow = 10,ncol = 60)
performance <- matrix(0, nrow = 10, ncol = 60)
mean_field <- matrix(0, nrow = 10, ncol = 60)
value <- NULL
sample_path <- 1
iteration <- 1
for (sample_path in 1:10)
{
L <- runif(B+1)
L <- L/sum(L)
L <- trunc(L*10^6)/10^6
for(iteration in 1:60)
{
# Q_table <- matrix(runif(length(state_space)*length(action_space),0,.01),nrow = length(state_space), ncol = length(action_space))
Q_a <- matrix(0,length(state_space), length(action_space))
Q_b <- matrix(0,length(state_space), length(action_space))
num_visited <<- matrix(0, nrow = length(state_space), ncol = length(action_space))
# dimnames(Q_a) <- list(state_space,action_space)
# dimnames(Q_b) <- list(state_space,action_space)
dimnames(num_visited) <- list(state_space,action_space)
# rm(.Random.seed, envir=globalenv())
state <- sample(state_space,1)
for(k in 1:400000)
{
sampled_state <- mean(sample(state_space,n,TRUE,prob=L))
Q_table <- .5 * (Q_a + Q_b)
ek <- max(.1,.999^k)
if (runif(1) > ek)
chosen_action <- action_space[which.min(Q_table[which(state_space==state),])] else
chosen_action <- sample(action_space,1)
r <- (.2 + sampled_state) * state + .5 * chosen_action
beta <- learning_rate(state,chosen_action,num_visited)
st <- ifelse(chosen_action==1,0,sample(state_space[which(state_space==state):(B+1)],1))
# Q_prime <- mellowmax(Q_table[which(state_space==st),],omega = -300)
if(runif(1)<.5)
Q_a[which(state_space==state),chosen_action+1] <- (1-beta) * Q_a[which(state_space==state),chosen_action+1] +
beta*(r + discount_factor*min(Q_b[which(state_space==st),]))      else
Q_b[which(state_space==state),chosen_action+1] <- (1-beta) * Q_b[which(state_space==state),chosen_action+1] +
beta*(r + discount_factor*min(Q_a[which(state_space==st),]))
# Q_table[which(state_space==state),chosen_action+1] <- (1-beta) * Q_table[which(state_space==state),chosen_action+1] +
#   beta*(r + discount_factor*min(Q_table[which(state_space==st),]))
# Q_table[which(state_space==state),chosen_action+1] <- (1-beta) * Q_table[which(state_space==state),chosen_action+1] +
#   beta*(r + discount_factor * Q_prime)
num_visited[which(state_space==state),chosen_action+1] <- num_visited[which(state_space==state),chosen_action+1] + 1
state <- st
}
Q_table <- .5 *(Q_a+Q_b)
pi <- sapply(state_space,FUN = soft_max)
P <- NULL
for (i in 1:(B+1))
{
P <- cbind(P,pi[,i] * L[i])
}
L_prime <- t(P[2,] %*% t(transition_1) + P[1,] %*% t(transition_0))
L_prime <- trunc(L_prime*10^6)/10^6
L <- L_prime
v <- apply(Q_table,1,min)
fit <- lm(v ~ state_space)
seg_fit <- segmented(fit)
policy[sample_path, iteration] <- seg_fit$psi[2]
performance[sample_path, iteration] <- mean(apply(Q_table,1,min))
mean_field[sample_path, iteration] <- sum(L*state_space)
print(c(sample_path, iteration, policy[sample_path, iteration], performance[sample_path, iteration], mean_field[sample_path,iteration]))
}
value <- rbind(value, apply(Q_table, 1, min))
}
plot(colMeans(performance),type = 'l')
plot(colMeans(policy), type='l',ylim = c(.3,.5))
colMeans(policy)
colMeans(performance)
num_visited
Q_table
policy
rm(.Random.seed, envir=globalenv())
library(segmented)
discount_factor <- .9
B <- 100
state_space <- seq(0,1,by=1/B)
action_space <- 0:1
n <- 100
options(scipen=999)
soft_max <- function(state, c=-2)
{
state <- round(state*B+1)
prob <- exp(c*Q_table[state,])
prob <- prob/sum(prob)
return(prob)
}
learning_rate <- function(state,action,num_visited,h=.55)
{
state <- round(state*B+1)
action <- round(action + 1)
return((num_visited[state,action]+1)^-h)
}
mellowmax <- function(Q, omega)
{
m <- max(Q)
Q <- Q - m
return(log(mean(exp(omega * Q)))/omega + m)
}
transition_0 <- NULL
transition_1 <- NULL
for (i in 1:length(state_space))
{
transition_1 <- cbind(transition_1, c(1,rep(0,B)))
}
for (i in 1:length(state_space))
{
transition_0 <- cbind(transition_0, c(rep(0,i-1), rep(1/(B-i+2),B-i+2)))
}
policy <- matrix(0,nrow = 10,ncol = 60)
performance <- matrix(0, nrow = 10, ncol = 60)
mean_field <- matrix(0, nrow = 10, ncol = 60)
value <- NULL
sample_path <- 1
iteration <- 1
for (sample_path in 1:10)
{
L <- runif(B+1)
L <- L/sum(L)
L <- trunc(L*10^6)/10^6
for(iteration in 1:60)
{
# Q_table <- matrix(runif(length(state_space)*length(action_space),0,.01),nrow = length(state_space), ncol = length(action_space))
Q_a <- matrix(0,length(state_space), length(action_space))
Q_b <- matrix(0,length(state_space), length(action_space))
num_visited <<- matrix(0, nrow = length(state_space), ncol = length(action_space))
# dimnames(Q_a) <- list(state_space,action_space)
# dimnames(Q_b) <- list(state_space,action_space)
dimnames(num_visited) <- list(state_space,action_space)
rm(.Random.seed, envir=globalenv())
state <- sample(state_space,1)
for(k in 1:400000)
{
sampled_state <- mean(sample(state_space,n,TRUE,prob=L))
Q_table <- .5 * (Q_a + Q_b)
ek <- max(.1,.999^k)
if (runif(1) > ek)
chosen_action <- action_space[which.min(Q_table[which(state_space==state),])] else
chosen_action <- sample(action_space,1)
r <- (.2 + sampled_state) * state + .5 * chosen_action
beta <- learning_rate(state,chosen_action,num_visited)
st <- ifelse(chosen_action==1,0,sample(state_space[which(state_space==state):(B+1)],1))
# Q_prime <- mellowmax(Q_table[which(state_space==st),],omega = -300)
if(runif(1)<.5)
Q_a[which(state_space==state),chosen_action+1] <- (1-beta) * Q_a[which(state_space==state),chosen_action+1] +
beta*(r + discount_factor*min(Q_b[which(state_space==st),]))      else
Q_b[which(state_space==state),chosen_action+1] <- (1-beta) * Q_b[which(state_space==state),chosen_action+1] +
beta*(r + discount_factor*min(Q_a[which(state_space==st),]))
# Q_table[which(state_space==state),chosen_action+1] <- (1-beta) * Q_table[which(state_space==state),chosen_action+1] +
#   beta*(r + discount_factor*min(Q_table[which(state_space==st),]))
# Q_table[which(state_space==state),chosen_action+1] <- (1-beta) * Q_table[which(state_space==state),chosen_action+1] +
#   beta*(r + discount_factor * Q_prime)
num_visited[which(state_space==state),chosen_action+1] <- num_visited[which(state_space==state),chosen_action+1] + 1
state <- st
}
Q_table <- .5 *(Q_a+Q_b)
pi <- sapply(state_space,FUN = soft_max)
P <- NULL
for (i in 1:(B+1))
{
P <- cbind(P,pi[,i] * L[i])
}
L_prime <- t(P[2,] %*% t(transition_1) + P[1,] %*% t(transition_0))
L_prime <- trunc(L_prime*10^6)/10^6
L <- L_prime
v <- apply(Q_table,1,min)
fit <- lm(v ~ state_space)
seg_fit <- segmented(fit)
policy[sample_path, iteration] <- seg_fit$psi[2]
performance[sample_path, iteration] <- mean(apply(Q_table,1,min))
mean_field[sample_path, iteration] <- sum(L*state_space)
print(c(sample_path, iteration, policy[sample_path, iteration], performance[sample_path, iteration], mean_field[sample_path,iteration]))
}
value <- rbind(value, apply(Q_table, 1, min))
}
colMeans(policy)
policy
performance
plot(colMeans(performance),type = 'l')
plot(colMeans(policy), type='l',ylim = c(.3,.5))
plot(colMeans(performance),type = 'l')
abline(h=3.88)
write.csv(policy, file = 'gmfq policy double.csv')
write.csv(performance, file = 'gmfq performance double.csv')
write.csv(mean_field, file = 'gmfq mean-field double.csv')
write.csv(value, file = 'gmfq value double.csv')
policy_d <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy double.csv',header = TRUE, colClasses = c("NULL", rep(NA,100)))
# policy_d <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified performance')
upper_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyd <- policy_d
# lower_policyd <- policy_d
colMeans(policy_d)
policy_n <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy mellowmax.csv',header = TRUE, colClasses = c("NULL", rep(NA,100)))
policy_n <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified policy 2 cutoff')
upper_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyn <- policy_n
# lower_policyn <- policy_n
length(dat_plot)
plot(colMeans(policy_d), type = 'l')
lines(colMeans(policy_n))
x <- seq(0,1,.01)
x <- 1:60
extrafont::loadfonts(device="win")
library(ggplot2)
dat_plot <- data.frame(rbind(cbind(x, colMeans(policy_d), lower_policyd, upper_policyd), cbind(x, colMeans(policy_n), lower_policyn, upper_policyn)))
names(dat_plot) <- c("Steps", "Policy", "lower", "upper")
dat_plot$group <- rep(c("Discretized", "Non-discretized"), each = length(x))
ggplot(dat_plot, aes(x = Steps, color = group, fill = group)) +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) +  # alpha 修改透明度
geom_line(aes(y = Policy)) + theme(panel.grid = element_blank(),
legend.position = "top",                      # legend 置顶
panel.border = element_blank(),
text = element_text(family = "STHeiti"),      # Mac 系统中中文绘图
plot.title = element_text(hjust = 0.5)) + labs(x = "State", y = "Value", title = "Value verus steps",
color = "", fill = "")
lower_policyn
upper_policyn
policy_n <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy mellowmax.csv',header = TRUE, colClasses = c("NULL", rep(NA,100)))
policy_d <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy double.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
# policy_d <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified performance')
upper_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyd <- policy_d
# lower_policyd <- policy_d
colMeans(policy_d)
policy_n <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy mellowmax.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
# policy_n <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified policy 2 cutoff')
upper_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyn <- policy_n
# lower_policyn <- policy_n
x <- 1:60
extrafont::loadfonts(device="win")
library(ggplot2)
dat_plot <- data.frame(rbind(cbind(x, colMeans(policy_d), lower_policyd, upper_policyd), cbind(x, colMeans(policy_n), lower_policyn, upper_policyn)))
names(dat_plot) <- c("Steps", "Policy", "lower", "upper")
dat_plot$group <- rep(c("Discretized", "Non-discretized"), each = length(x))
ggplot(dat_plot, aes(x = Steps, color = group, fill = group)) +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) +  # alpha 修改透明度
geom_line(aes(y = Policy)) + theme(panel.grid = element_blank(),
legend.position = "top",                      # legend 置顶
panel.border = element_blank(),
text = element_text(family = "STHeiti"),      # Mac 系统中中文绘图
plot.title = element_text(hjust = 0.5)) + labs(x = "State", y = "Value", title = "Value verus steps",
color = "", fill = "")
policy_d <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq performance double.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
# policy_d <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified performance')
upper_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyd <- policy_d
# lower_policyd <- policy_d
colMeans(policy_d)
policy_n <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy mellowmax.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
# policy_n <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified policy 2 cutoff')
gmfq_policy <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy mellowmax.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
upper_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyn <- policy_n
# lower_policyn <- policy_n
upper_gmfq <- apply(gmfq_policy, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_gmfq <- apply(gmfq_policy, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
dat_plot <- data.frame(rbind(cbind(x, colMeans(policy_d), lower_policyd, upper_policyd), cbind(x, colMeans(policy_n), lower_policyn, upper_policyn),
cbind(x, colMeans(gmfq_policy), lower_gmfq, upper_gmfq)))
names(dat_plot) <- c("Steps", "Policy", "lower", "upper")
dat_plot$group <- rep(c("Discretized", "Non-discretized"), each = length(x))
dat_plot
# policy_n <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified policy 2 cutoff')
gmfq_policy <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq performance mellowmax.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
upper_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyn <- policy_n
# lower_policyn <- policy_n
upper_gmfq <- apply(gmfq_policy, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_gmfq <- apply(gmfq_policy, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
dat_plot <- data.frame(rbind(cbind(x, colMeans(policy_d), lower_policyd, upper_policyd), cbind(x, colMeans(policy_n), lower_policyn, upper_policyn),
cbind(x, colMeans(gmfq_policy), lower_gmfq, upper_gmfq)))
names(dat_plot) <- c("Steps", "Policy", "lower", "upper")
dat_plot$group <- rep(c("Discretized", "Non-discretized"), each = length(x))
dat_plot
# policy_n <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified policy 2 cutoff')
gmfq_policy <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
# policy_n <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified policy 2 cutoff')
gmfq_policy <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy n=10.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
upper_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyn <- policy_n
# lower_policyn <- policy_n
upper_gmfq <- apply(gmfq_policy, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_gmfq <- apply(gmfq_policy, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
dat_plot <- data.frame(rbind(cbind(x, colMeans(policy_d), lower_policyd, upper_policyd), cbind(x, colMeans(policy_n), lower_policyn, upper_policyn),
cbind(x, colMeans(gmfq_policy), lower_gmfq, upper_gmfq)))
names(dat_plot) <- c("Steps", "Policy", "lower", "upper")
dat_plot$group <- rep(c("Discretized", "Non-discretized",'third'), each = length(x))
ggplot(dat_plot, aes(x = Steps, color = group, fill = group)) +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) +  # alpha 修改透明度
geom_line(aes(y = Policy)) + theme(panel.grid = element_blank(),
legend.position = "top",                      # legend 置顶
panel.border = element_blank(),
text = element_text(family = "STHeiti"),      # Mac 系统中中文绘图
plot.title = element_text(hjust = 0.5)) + labs(x = "State", y = "Value", title = "Value verus steps",
color = "", fill = "")
policy_d <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq policy double.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
upper_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
dat_plot <- data.frame(rbind(cbind(x, colMeans(policy_d), lower_policyd, upper_policyd), cbind(x, colMeans(policy_n), lower_policyn, upper_policyn),
cbind(x, colMeans(gmfq_policy), lower_gmfq, upper_gmfq)))
names(dat_plot) <- c("Steps", "Policy", "lower", "upper")
dat_plot$group <- rep(c("Discretized", "Non-discretized",'third'), each = length(x))
ggplot(dat_plot, aes(x = Steps, color = group, fill = group)) +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) +  # alpha 修改透明度
geom_line(aes(y = Policy)) + theme(panel.grid = element_blank(),
legend.position = "top",                      # legend 置顶
panel.border = element_blank(),
text = element_text(family = "STHeiti"),      # Mac 系统中中文绘图
plot.title = element_text(hjust = 0.5)) + labs(x = "State", y = "Value", title = "Value verus steps",
color = "", fill = "")
policy_d <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq performance double.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
# policy_d <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified performance')
upper_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyd <- apply(policy_d, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyd <- policy_d
# lower_policyd <- policy_d
colMeans(policy_d)
policy_n <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq performance mellowmax.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
# policy_n <- read.table('C:\\Users\\zxczx\\PycharmProjects\\pythonProject\\unified policy 2 cutoff')
gmfq_policy <- read.csv('C:\\Users\\zxczx\\Documents\\gmfq performance n=10.csv',header = TRUE, colClasses = c("NULL", rep(NA,60)))
upper_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_policyn <- apply(policy_n, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
# upper_policyn <- policy_n
# lower_policyn <- policy_n
upper_gmfq <- apply(gmfq_policy, 2, function(x) t.test(x,conf.level = .95)$conf.int[2])
lower_gmfq <- apply(gmfq_policy, 2, function(x) t.test(x,conf.level = .95)$conf.int[1])
dat_plot <- data.frame(rbind(cbind(x, colMeans(policy_d), lower_policyd, upper_policyd), cbind(x, colMeans(policy_n), lower_policyn, upper_policyn),
cbind(x, colMeans(gmfq_policy), lower_gmfq, upper_gmfq)))
names(dat_plot) <- c("Steps", "Policy", "lower", "upper")
dat_plot$group <- rep(c("Discretized", "Non-discretized",'third'), each = length(x))
ggplot(dat_plot, aes(x = Steps, color = group, fill = group)) +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) +  # alpha 修改透明度
geom_line(aes(y = Policy)) + theme(panel.grid = element_blank(),
legend.position = "top",                      # legend 置顶
panel.border = element_blank(),
text = element_text(family = "STHeiti"),      # Mac 系统中中文绘图
plot.title = element_text(hjust = 0.5)) + labs(x = "State", y = "Value", title = "Value verus steps",
color = "", fill = "")
x <- matrix(2,2,3,45,5,7)
y <- matrix(34,38,38,53,50,60,70)
x <- matrix(data=c(2,2,3,45,5,7))
y <- matrix(data=c(34,38,38,53,50,60,70))
x
x <- matrix(data=c(2,2,3,4,5,5,7))
y <- matrix(data=c(34,38,38,53,50,60,70))
x
y
lm(y~x)
t(x)
t(x) %*% x
solve(t(x) %*% x)
solve(t(x) %*% x) * 132
solve(t(x) %*% x) %*% t(x) %*% y
cbind(matrix(data = c(1,1,1,1,1,1,1)),x)
z <- cbind(matrix(data = c(1,1,1,1,1,1,1)),x)
t(z) %*% z
solve(t(z) %*% z) %*% t(z) %*% y
13272 - 392 * 924 / 28
392 ^ 2 / 28
5288 * 23
5288 * 23 - 336
121288 / 23
392 / 28
392 * 924 / 28
x <- matrix(data = c(1,1,1,1,1,6,7,7,8,8,4.5,4.6,4.5,4.7,4.6), nrow=3,ncol=5, byrow = T)
x
y <- matrix(data = c(1.3,1.5,1.9,1.6,1.7))
y
x %*% y
x <- matrix(data = c(1,1,1,1,1,6,7,7,8,8,4.5,4.6,4.5,4.7,4.6), nrow=3,ncol=5, byrow = T)
y <- matrix(data = c(1.3,1.5,1.8,1.6,1.7))
x %*% y
matrix(data = c(1522.73,26.87,-374.67,26.87,.93,-7.33,-374.67,-7.33,93.33),3,3)
matrix(data = c(1522.73,26.87,-374.67,26.87,.93,-7.33,-374.67,-7.33,93.33),3,3) %*% (x %*% y)
beta <- matrix(data = c(1522.73,26.87,-374.67,26.87,.93,-7.33,-374.67,-7.33,93.33),3,3) %*% (x %*% y)
matrix(data=c(1,8,4.6))
beta
t(beta) %*% matrix(data=c(1,8,4.6))
t(beta) %*% matrix(data=c(1,7,4.6))
x <- c(6.8,7,7.1,7.2,7.4)
x
y <- c(.8,1.2,.9,.9,1.5)
cov(x,y)
corr(x,y)
cor(x,y)
var(x)
var(y)
cov(x,y)
shiny::runApp('temp')
file.path(getwd(),'pop2006.csv')
getwd()
setwd('C:\STAT5702')
runApp('temp')
file.path(getwd(),'pop2006')
file.path(getwd(),'pop2006.csv')
read.csv(file.path(getwd(),'pop2006.csv'))
read.csv('pop2006.csv')
runApp('temp')
getwd()
setwd('C:\\STAT5702')
getwd()
read.csv('pop2006.csv')
runApp('~/temp')
runApp('~/temp')
runApp('~/temp')
runApp('~/temp')
runApp('~/temp')
read.csv("pop2006.csv")
x = read.csv("pop2006.csv")
x[-1, 3]
x[-1]
x[1]
x[1,3]
x[-1,3]
x[-1,1]
x[,1]
x[-1]
x[-2]
x[-2,1]
x[-1,3]
x <- x[-1,3]
range(x)
runApp('~/temp')
runApp('~/temp')
runApp('~/temp')
